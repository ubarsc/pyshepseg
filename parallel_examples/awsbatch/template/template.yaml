---
AWSTemplateFormatVersion: '2010-09-09'
Description: 'UBARSC AWS Batch Tiled Segmentation using CloudFormation'
Resources:
  VPC:
    Type: AWS::EC2::VPC
    Properties:
      CidrBlock: 10.0.0.0/16
  InternetGateway:
    Type: AWS::EC2::InternetGateway
  RouteTable:
    Type: AWS::EC2::RouteTable
    Properties:
      VpcId:
        Ref: VPC
  VPCGatewayAttachment:
    Type: AWS::EC2::VPCGatewayAttachment
    Properties:
      VpcId:
        Ref: VPC
      InternetGatewayId:
        Ref: InternetGateway
  SecurityGroup:
    Type: AWS::EC2::SecurityGroup
    Properties:
      GroupDescription: EC2 Security Group for instances launched in the VPC by Batch
      VpcId:
        Ref: VPC
  Subnet1:
    Type: AWS::EC2::Subnet
    Properties:
      CidrBlock: 10.0.0.0/24
      VpcId:
        Ref: VPC
      # yes we do need public ips or NAT
      # See https://repost.aws/knowledge-center/batch-job-stuck-runnable-status
      MapPublicIpOnLaunch: 'True'
      AvailabilityZone: !Select 
        - 0
        - Fn::GetAZs: !Ref 'AWS::Region'
  Subnet2:
    Type: AWS::EC2::Subnet
    Properties:
      CidrBlock: 10.0.1.0/24
      VpcId:
        Ref: VPC
      MapPublicIpOnLaunch: 'True'
      AvailabilityZone: !Select 
        - 1
        - Fn::GetAZs: !Ref 'AWS::Region'
  Subnet3:
    Type: AWS::EC2::Subnet
    Properties:
      CidrBlock: 10.0.2.0/24
      VpcId:
        Ref: VPC
      MapPublicIpOnLaunch: 'True'
      AvailabilityZone: !Select 
        - 2
        - Fn::GetAZs: !Ref 'AWS::Region'
  Route:
    Type: AWS::EC2::Route
    Properties:
      RouteTableId:
        Ref: RouteTable
      DestinationCidrBlock: 0.0.0.0/0
      GatewayId:
        Ref: InternetGateway
  # Allow S3 traffic to go through an internet gateway
  S3GatewayEndpoint:
    Type: AWS::EC2::VPCEndpoint
    Properties:
      VpcEndpointType: 'Gateway'
      VpcId: !Ref VPC
      ServiceName: !Sub 'com.amazonaws.${AWS::Region}.s3'
      PolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Principal: '*'
            Action: 
               - 's3:*Object'
               - 's3:ListBucket'
            Resource: 
               - 'arn:aws:s3:::*/*'
               - 'arn:aws:s3:::*'
      RouteTableIds:
        - !Ref RouteTable
  SubnetRouteTableAssociation1:
    Type: AWS::EC2::SubnetRouteTableAssociation
    Properties:
      RouteTableId:
        Ref: RouteTable
      SubnetId:
        Ref: Subnet1
  SubnetRouteTableAssociation2:
    Type: AWS::EC2::SubnetRouteTableAssociation
    Properties:
      RouteTableId:
        Ref: RouteTable
      SubnetId:
        Ref: Subnet2
  SubnetRouteTableAssociation3:
    Type: AWS::EC2::SubnetRouteTableAssociation
    Properties:
      RouteTableId:
        Ref: RouteTable
      SubnetId:
        Ref: Subnet3
  IamInstanceProfile:
    Type: AWS::IAM::InstanceProfile
    Properties:
      Roles:
      - Ref: EcsInstanceRole
  SubmitJobsManagedPolicy:
    Type: AWS::IAM::ManagedPolicy
    Properties:
      Description: Policy for allowing web site to submit Batch jobs
      Path: /
      PolicyDocument:
        Version: '2012-10-17'
        Statement:
        - Effect: Allow
          Action: 'batch:SubmitJob'
          Resource:
            # can't use resources directly as causes a circular dependency
            # but we know what the names will be
            #- !Ref BatchProcessingJobDefinitionTile
            #- !Ref BatchProcessingJobDefinitionStitch
            #- !Ref BatchProcessingJobQueue
            - !Sub 'arn:aws:batch:${AWS::Region}:${AWS::AccountId}:job-definition/PyShepSegBatchJobDefinitionTile:*'
            - !Sub 'arn:aws:batch:${AWS::Region}:${AWS::AccountId}:job-definition/PyShepSegBatchJobDefinitionStitch:*'
            - !Sub 'arn:aws:batch:${AWS::Region}:${AWS::AccountId}:job-queue/PyShepSegBatchProcessingJobQueue'
  EcsInstanceRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: '2008-10-17'
        Statement:
        - Sid: ''
          Effect: Allow
          Principal:
            Service: ec2.amazonaws.com
          Action: sts:AssumeRole
      ManagedPolicyArns:
      - arn:aws:iam::aws:policy/service-role/AmazonEC2ContainerServiceforEC2Role
      - arn:aws:iam::aws:policy/AmazonS3FullAccess
      - arn:aws:iam::aws:policy/service-role/AWSBatchServiceEventTargetRole
      - !Ref SubmitJobsManagedPolicy
  BatchRepository:
    Type: AWS::ECR::Repository
    Properties:
      RepositoryName: pyshepseg
      LifecyclePolicy:
        LifecyclePolicyText: |
          {
            "rules": [
                {
                    "rulePriority": 1,
                    "description": "Expire images older than 1 day",
                    "selection": {
                        "tagStatus": "untagged",
                        "countType": "sinceImagePushed",
                        "countUnit": "days",
                        "countNumber": 1
                    },
                    "action": {
                        "type": "expire"
                    }
                }
            ]
          }
  # Job for doing individual tiles
  BatchProcessingJobDefinitionTile:
    Type: AWS::Batch::JobDefinition
    Properties:
      Type: container
      JobDefinitionName: PyShepSegBatchJobDefinitionTile
      ContainerProperties:
        Image: !Join ['', [!GetAtt BatchRepository.RepositoryUri, ":latest"]]
        Vcpus: 1
        Memory: 16000
      RetryStrategy:
        Attempts: 1
  # Job for stitching tiles together 
  BatchProcessingJobDefinitionStitch:
    Type: AWS::Batch::JobDefinition
    Properties:
      Type: container
      JobDefinitionName: PyShepSegBatchJobDefinitionStitch
      ContainerProperties:
        Image: !Join ['', [!GetAtt BatchRepository.RepositoryUri, ":latest"]]
        Vcpus: 1
        Memory: 8000
      RetryStrategy:
        Attempts: 1
  BatchProcessingJobQueue:
    Type: AWS::Batch::JobQueue
    Properties:
      JobQueueName: PyShepSegBatchProcessingJobQueue
      Priority: 1
      ComputeEnvironmentOrder:
      - Order: 1
        ComputeEnvironment:
          Ref: ComputeEnvironment
  ComputeEnvironment:
    Type: AWS::Batch::ComputeEnvironment
    Properties:
      Type: MANAGED
      ComputeResources:
        Type: EC2
        MinvCpus: 0
        DesiredvCpus: 0
        MaxvCpus: 1024
        InstanceTypes:
        #- a1.medium
        - optimal
        Subnets:
        - Ref: Subnet1
        - Ref: Subnet2
        - Ref: Subnet3
        SecurityGroupIds:
        - Ref: SecurityGroup
        InstanceRole:
          Ref: IamInstanceProfile
        LaunchTemplate:
          LaunchTemplateId: !Ref LaunchTemplate
          Version: !GetAtt LaunchTemplate.LatestVersionNumber
  # Launch template - increase default storage available
  # https://repost.aws/knowledge-center/batch-job-failure-disk-space
  # https://docs.aws.amazon.com/batch/latest/userguide/launch-templates.html
  # Probably don't need this for all job types, but that would mean different queues
  LaunchTemplate:
    Type: AWS::EC2::LaunchTemplate
    Properties:
      LaunchTemplateData:
         BlockDeviceMappings:
           - DeviceName: /dev/xvda
             Ebs:
               VolumeType: gp2
               VolumeSize: 1024
               DeleteOnTermination: true
       
Outputs:
  ComputeEnvironmentArn:
    Value:
      Ref: ComputeEnvironment
  BatchProcessingJobQueueArn:
    Value:
      Ref: BatchProcessingJobQueue
  BatchProcessingJobDefinitionArn:
    Value:
      Ref: BatchProcessingJobDefinitionTile
      Ref: BatchProcessingJobDefinitionStitch
